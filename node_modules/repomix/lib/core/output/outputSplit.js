var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
import path from 'node:path';
import pc from 'picocolors';
import { RepomixError } from '../../shared/errorHandle.js';
export const getRootEntry = (relativeFilePath) => {
    const normalized = relativeFilePath.replaceAll(path.win32.sep, path.posix.sep);
    const [first] = normalized.split('/');
    return first || normalized;
};
export const buildOutputSplitGroups = (processedFiles, allFilePaths) => {
    const groupsByRootEntry = new Map();
    for (const filePath of allFilePaths) {
        const rootEntry = getRootEntry(filePath);
        const existing = groupsByRootEntry.get(rootEntry);
        if (existing) {
            existing.allFilePaths.push(filePath);
        }
        else {
            groupsByRootEntry.set(rootEntry, { rootEntry, processedFiles: [], allFilePaths: [filePath] });
        }
    }
    for (const processedFile of processedFiles) {
        const rootEntry = getRootEntry(processedFile.path);
        const existing = groupsByRootEntry.get(rootEntry);
        if (existing) {
            existing.processedFiles.push(processedFile);
        }
        else {
            groupsByRootEntry.set(rootEntry, {
                rootEntry,
                processedFiles: [processedFile],
                allFilePaths: [processedFile.path],
            });
        }
    }
    return [...groupsByRootEntry.values()].sort((a, b) => a.rootEntry.localeCompare(b.rootEntry));
};
export const buildSplitOutputFilePath = (baseFilePath, partIndex) => {
    const ext = path.extname(baseFilePath);
    if (!ext) {
        return `${baseFilePath}.${partIndex}`;
    }
    const baseWithoutExt = baseFilePath.slice(0, -ext.length);
    return `${baseWithoutExt}.${partIndex}${ext}`;
};
const getUtf8ByteLength = (content) => Buffer.byteLength(content, 'utf8');
const makeChunkConfig = (baseConfig, partIndex) => {
    if (partIndex === 1) {
        return baseConfig;
    }
    // For non-first chunks, disable git diffs/logs to avoid repeating large sections.
    const git = Object.assign(Object.assign({}, baseConfig.output.git), { includeDiffs: false, includeLogs: false });
    return Object.assign(Object.assign({}, baseConfig), { output: Object.assign(Object.assign({}, baseConfig.output), { git }) });
};
const renderGroups = (groupsToRender, partIndex, rootDirs, baseConfig, gitDiffResult, gitLogResult, filePathsByRoot, generateOutput) => __awaiter(void 0, void 0, void 0, function* () {
    const chunkProcessedFiles = groupsToRender.flatMap((g) => g.processedFiles);
    const chunkAllFilePaths = groupsToRender.flatMap((g) => g.allFilePaths);
    const chunkConfig = makeChunkConfig(baseConfig, partIndex);
    return yield generateOutput(rootDirs, chunkConfig, chunkProcessedFiles, chunkAllFilePaths, partIndex === 1 ? gitDiffResult : undefined, partIndex === 1 ? gitLogResult : undefined, filePathsByRoot);
});
export const generateSplitOutputParts = (_a) => __awaiter(void 0, [_a], void 0, function* ({ rootDirs, baseConfig, processedFiles, allFilePaths, maxBytesPerPart, gitDiffResult, gitLogResult, progressCallback, filePathsByRoot, deps, }) {
    if (!Number.isSafeInteger(maxBytesPerPart) || maxBytesPerPart <= 0) {
        throw new RepomixError(`Invalid maxBytesPerPart: ${maxBytesPerPart}`);
    }
    const groups = buildOutputSplitGroups(processedFiles, allFilePaths);
    if (groups.length === 0) {
        return [];
    }
    const parts = [];
    let currentGroups = [];
    let currentContent = '';
    let currentBytes = 0;
    // Note: This algorithm has O(NÂ²) complexity where N is the number of groups.
    // For each group, we render all accumulated groups to measure the exact output size.
    // This approach is intentional because:
    // 1. The final output size cannot be predicted by simple addition - the output includes
    //    a file tree structure and template formatting (XML/Markdown) that vary non-linearly.
    // 2. Headers, footers, and file tree size change based on the combination of groups.
    // 3. For typical repositories with ~10-20 top-level directories, this is acceptable.
    // If performance becomes an issue, consider caching individual group content sizes
    // and estimating combined sizes with a safety margin.
    for (const group of groups) {
        const partIndex = parts.length + 1;
        const nextGroups = [...currentGroups, group];
        progressCallback(`Generating output... (part ${partIndex}) ${pc.dim(`evaluating ${group.rootEntry}`)}`);
        const nextContent = yield renderGroups(nextGroups, partIndex, rootDirs, baseConfig, gitDiffResult, gitLogResult, filePathsByRoot, deps.generateOutput);
        const nextBytes = getUtf8ByteLength(nextContent);
        if (nextBytes <= maxBytesPerPart) {
            currentGroups = nextGroups;
            currentContent = nextContent;
            currentBytes = nextBytes;
            continue;
        }
        if (currentGroups.length === 0) {
            throw new RepomixError(`Cannot split output: root entry '${group.rootEntry}' exceeds max size. ` +
                `Part size ${nextBytes.toLocaleString()} bytes > limit ${maxBytesPerPart.toLocaleString()} bytes.`);
        }
        // Finalize current part and start a new one with the current group.
        parts.push({
            index: partIndex,
            filePath: buildSplitOutputFilePath(baseConfig.output.filePath, partIndex),
            content: currentContent,
            byteLength: currentBytes,
            groups: currentGroups,
        });
        const newPartIndex = parts.length + 1;
        progressCallback(`Generating output... (part ${newPartIndex}) ${pc.dim(`evaluating ${group.rootEntry}`)}`);
        const singleGroupContent = yield renderGroups([group], newPartIndex, rootDirs, baseConfig, gitDiffResult, gitLogResult, filePathsByRoot, deps.generateOutput);
        const singleGroupBytes = getUtf8ByteLength(singleGroupContent);
        if (singleGroupBytes > maxBytesPerPart) {
            throw new RepomixError(`Cannot split output: root entry '${group.rootEntry}' exceeds max size. ` +
                `Part size ${singleGroupBytes.toLocaleString()} bytes > limit ${maxBytesPerPart.toLocaleString()} bytes.`);
        }
        currentGroups = [group];
        currentContent = singleGroupContent;
        currentBytes = singleGroupBytes;
    }
    if (currentGroups.length > 0) {
        const finalIndex = parts.length + 1;
        parts.push({
            index: finalIndex,
            filePath: buildSplitOutputFilePath(baseConfig.output.filePath, finalIndex),
            content: currentContent,
            byteLength: currentBytes,
            groups: currentGroups,
        });
    }
    return parts;
});
//# sourceMappingURL=outputSplit.js.map